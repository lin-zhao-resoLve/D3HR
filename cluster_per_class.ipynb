{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "673a371b-944a-4e0a-9f76-19a415569714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import MiniBatchKMeans,KMeans,DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.metrics import rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from collections import Counter, defaultdict\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f17a65-81c1-4d01-950a-d4a6d52e0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mapping(mapping_file):\n",
    "    wnid_to_index = {}\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        for line in f:\n",
    "            wnid, index = line.strip().split('\\t')\n",
    "            wnid_to_index[wnid] = int(index)\n",
    "    return wnid_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9f4241-5dc3-48d9-af45-be584443813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_space(x, y, z):\n",
    "    init_count = 0\n",
    "    for count in x:\n",
    "        count = count + init_count\n",
    "        y.append(z[init_count:count])\n",
    "        init_count = count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92716cc8-27eb-4a60-9001-59aad8d64ba5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Perform Kmeans++ to each class with `n_clusters = 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef639d4-cae6-439d-a631-be28e320ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnid_to_index = load_mapping(os.path.join('ds_inf/tiny-imagenet-200', 'tiny-imagenet-mapping.txt'))\n",
    "input_dir = '/scratch/zhao.lin1/dataset/tiny-imagenet-200/train_vit_image_feature_CLS'\n",
    "save_dir = '/scratch/zhao.lin1/dataset/tiny-imagenet-200/key50_far_latents_train_vit_image_feature_CLS'\n",
    "n_clusters = 1\n",
    "n_key = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd4553e-131c-4d9b-b4b5-1f0efb3308e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = []\n",
    "labels = []\n",
    "file_paths = []\n",
    "result = {}  # Initialize result as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1458a7a0-328e-40cc-b1ed-6ea9d6050fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result was saved in ds_inf/vit_Kmeans++_1_cluster_per_class.json\n"
     ]
    }
   ],
   "source": [
    "for class_idx, class_folder in enumerate(os.listdir(input_dir)):\n",
    "    class_dir = os.path.join(input_dir, class_folder)\n",
    "    \n",
    "    if os.path.isdir(class_dir):\n",
    "        file_paths = []\n",
    "        latents = []\n",
    "\n",
    "        # Collect latents and file paths\n",
    "        for file_name in sorted(os.listdir(class_dir)):\n",
    "            if file_name.endswith('.pt'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                file_paths.append(file_path)\n",
    "                \n",
    "                latent = torch.load(file_path, weights_only=True)  \n",
    "                latents.append(latent.cpu().numpy())\n",
    "\n",
    "        # Process latents if any are found\n",
    "        if latents:\n",
    "            class_latents = np.stack(latents).astype(np.float32)\n",
    "            class_latents_normalized = normalize(class_latents, norm='l2', axis=1)\n",
    "\n",
    "            # Perform KMeans clustering\n",
    "            kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=0)\n",
    "            kmeans.fit(class_latents_normalized)\n",
    "            centroids = kmeans.cluster_centers_\n",
    "\n",
    "            # Calculate distances to the centroid\n",
    "            distances = np.linalg.norm(class_latents_normalized - centroids[kmeans.labels_], axis=1)\n",
    "            \n",
    "            # Sort by distance and select the top n_key farthest latents\n",
    "            sorted_indices = np.argsort(distances)[::-1]  # Sort descending by distance\n",
    "            top_n_indices = sorted_indices[:n_key]  # Get exactly the top n_key indices\n",
    "\n",
    "            top_n_distances = distances[top_n_indices]\n",
    "\n",
    "            key = class_folder\n",
    "            if key not in result:\n",
    "                result[key] = []\n",
    "\n",
    "            for i in range(n_key):\n",
    "                idx = top_n_indices[i]\n",
    "                file_name = os.path.basename(file_paths[idx]).replace('.pt', '.JPEG')\n",
    "                \n",
    "                result[key].append({\n",
    "                    \"index\": int(idx),\n",
    "                    \"file_name\": file_name,\n",
    "                    \"distance\": float(top_n_distances[i])\n",
    "                })\n",
    "\n",
    "# Save result as a JSON file\n",
    "output_json_path = 'ds_inf/vit_Kmeans++_1_cluster_per_class.json'\n",
    "with open(output_json_path, 'w') as f:\n",
    "    json.dump(result, f, indent=4)\n",
    "\n",
    "print(f\"Result was saved in {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d7ee764-d2ac-4fe1-80eb-dd7f938b75f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n01443537 类别中 unique 的 distance 数量：50\n"
     ]
    }
   ],
   "source": [
    "# 读取 JSON 文件\n",
    "with open('ds_inf/vit_Kmeans++_1_cluster_per_class.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 替换 'class_name' 为你要查询的类别名称\n",
    "class_name = 'n01443537'  # 指定要查询的类别\n",
    "if class_name in data:\n",
    "    # 提取该类别下所有的 distance 值\n",
    "    distances = [entry[\"distance\"] for entry in data[class_name]]\n",
    "    \n",
    "    # 获取唯一 distance 值的个数\n",
    "    unique_distances = set(distances)\n",
    "    print(f\"{class_name} 类别中 unique 的 distance 数量：{len(unique_distances)}\")\n",
    "else:\n",
    "    print(f\"类别 '{class_name}' 不在数据中\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dffb06-8304-4a27-989b-1bd538fa16d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Perform Kmeans++ to each class with `n_clusters = 50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee57f5f0-9d6d-41c4-8964-b0ec93fca5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnid_to_index = load_mapping(os.path.join('ds_inf/tiny-imagenet-200', 'tiny-imagenet-mapping.txt'))\n",
    "input_dir = '/scratch/zhao.lin1/dataset/tiny-imagenet-200/train_vit_image_feature_CLS'\n",
    "save_dir = '/scratch/zhao.lin1/dataset/tiny-imagenet-200/key50_far_latents_train_vit_image_feature_CLS'\n",
    "n_clusters = 50\n",
    "n_key = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59575a47-5e62-4185-b764-9e17e7d374f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = []\n",
    "labels = []\n",
    "file_paths = []\n",
    "result = {}  # Initialize result as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c283bbe-089b-44a8-aac9-4b3539332f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result was saved in ds_inf/vit_Kmeans++_50_cluster_per_class.json\n"
     ]
    }
   ],
   "source": [
    "for class_idx, class_folder in enumerate(os.listdir(input_dir)):\n",
    "    class_dir = os.path.join(input_dir, class_folder)\n",
    "\n",
    "    if os.path.isdir(class_dir):\n",
    "        file_paths = []\n",
    "        latents = []\n",
    "\n",
    "        # Collect latents and file paths\n",
    "        for file_name in sorted(os.listdir(class_dir)):\n",
    "            if file_name.endswith('.pt'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                file_paths.append(file_path)\n",
    "                \n",
    "                latent = torch.load(file_path, weights_only=True)  \n",
    "                latents.append(latent.cpu().numpy())\n",
    "\n",
    "        # Process latents if any are found\n",
    "        if latents:\n",
    "            class_latents = np.stack(latents).astype(np.float32)\n",
    "            class_latents_normalized = normalize(class_latents, norm='l2', axis=1)\n",
    "\n",
    "            # Perform KMeans clustering\n",
    "            kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=0)\n",
    "            kmeans.fit(class_latents_normalized)\n",
    "            centroids = kmeans.cluster_centers_\n",
    "\n",
    "            # Calculate distances to the centroid for each latent in each cluster\n",
    "            distances = np.linalg.norm(class_latents_normalized - centroids[kmeans.labels_], axis=1)\n",
    "\n",
    "            # For each cluster, select the top n_key farthest latents\n",
    "            for cluster_idx in range(n_clusters):\n",
    "                # Get indices of latents belonging to the current cluster\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_idx)[0]\n",
    "                cluster_distances = distances[cluster_indices]\n",
    "                cluster_file_paths = [file_paths[i] for i in cluster_indices]\n",
    "\n",
    "                # Sort by distance and select top n_key latents\n",
    "                sorted_indices = np.argsort(cluster_distances)[::-1]  # Sort descending by distance\n",
    "                top_n_indices = sorted_indices[:n_key]  # Select top n_key indices\n",
    "\n",
    "                top_n_distances = cluster_distances[top_n_indices]\n",
    "\n",
    "                # Ensure class key is in the result dictionary\n",
    "                key = class_folder\n",
    "                if key not in result:\n",
    "                    result[key] = []\n",
    "\n",
    "                # Append the result for the current cluster\n",
    "                for i in range(n_key):\n",
    "                    idx = cluster_indices[top_n_indices[i]]  # Get the original index of the latent\n",
    "                    file_name = os.path.basename(cluster_file_paths[i]).replace('.pt', '.JPEG')\n",
    "                    \n",
    "                    result[key].append({\n",
    "                        \"index\": int(idx),\n",
    "                        \"file_name\": file_name,\n",
    "                        \"distance\": float(top_n_distances[i])\n",
    "                    })\n",
    "\n",
    "# Save the result as a JSON file\n",
    "output_json_path = 'ds_inf/vit_Kmeans++_50_cluster_per_class.json'\n",
    "with open(output_json_path, 'w') as f:\n",
    "    json.dump(result, f, indent=4)\n",
    "\n",
    "print(f\"Result was saved in {output_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade6f0c2-3c4b-4287-aa3e-7f5700138888",
   "metadata": {},
   "source": [
    "# 最近的50个，`n_cluster=1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17c84cba-f70d-4dd7-a090-0bb702dbc319",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnid_to_index = load_mapping(os.path.join('ds_inf/tiny-imagenet-200', 'tiny-imagenet-mapping.txt'))\n",
    "input_dir = '/scratch/zhao.lin1/dataset/tiny-imagenet-200/train_vit_image_feature_CLS'\n",
    "save_dir = '/scratch/zhao.lin1/dataset/tiny-imagenet-200/key50_far_latents_train_vit_image_feature_CLS'\n",
    "n_clusters = 1\n",
    "n_key = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae52b67a-2179-4d25-8a91-a4adee4b2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = []\n",
    "labels = []\n",
    "file_paths = []\n",
    "result = {}  # Initialize result as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61a19bd9-e101-4351-8d08-f056c8ab9c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result was saved in ds_inf/vit_Kmeans++_closest_1_cluster_per_class.json\n"
     ]
    }
   ],
   "source": [
    "for class_idx, class_folder in enumerate(os.listdir(input_dir)):\n",
    "    class_dir = os.path.join(input_dir, class_folder)\n",
    "\n",
    "    if os.path.isdir(class_dir):\n",
    "        file_paths = []\n",
    "        latents = []\n",
    "\n",
    "        # Collect latents and file paths\n",
    "        for file_name in sorted(os.listdir(class_dir)):\n",
    "            if file_name.endswith('.pt'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                file_paths.append(file_path)\n",
    "                \n",
    "                latent = torch.load(file_path, weights_only=True)  \n",
    "                latents.append(latent.cpu().numpy())\n",
    "\n",
    "        # Process latents if any are found\n",
    "        if latents:\n",
    "            class_latents = np.stack(latents).astype(np.float32)\n",
    "            class_latents_normalized = normalize(class_latents, norm='l2', axis=1)\n",
    "\n",
    "            # Perform KMeans clustering\n",
    "            kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=0)\n",
    "            kmeans.fit(class_latents_normalized)\n",
    "            centroids = kmeans.cluster_centers_\n",
    "\n",
    "            # Calculate distances to the centroid for each latent in each cluster\n",
    "            distances = np.linalg.norm(class_latents_normalized - centroids[kmeans.labels_], axis=1)\n",
    "\n",
    "            # For each cluster, select the top n_key farthest latents\n",
    "            for cluster_idx in range(n_clusters):\n",
    "                # Get indices of latents belonging to the current cluster\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_idx)[0]\n",
    "                cluster_distances = distances[cluster_indices]\n",
    "                cluster_file_paths = [file_paths[i] for i in cluster_indices]\n",
    "\n",
    "                # Sort by distance and select top n_key latents\n",
    "                sorted_indices = np.argsort(cluster_distances)  # Sort descending by distance\n",
    "                top_n_indices = sorted_indices[:n_key]  # Select top n_key indices\n",
    "\n",
    "                top_n_distances = cluster_distances[top_n_indices]\n",
    "\n",
    "                # Ensure class key is in the result dictionary\n",
    "                key = class_folder\n",
    "                if key not in result:\n",
    "                    result[key] = []\n",
    "\n",
    "                # Append the result for the current cluster\n",
    "                for i in range(n_key):\n",
    "                    idx = cluster_indices[top_n_indices[i]]  # Get the original index of the latent\n",
    "                    file_name = os.path.basename(cluster_file_paths[i]).replace('.pt', '.JPEG')\n",
    "                    \n",
    "                    result[key].append({\n",
    "                        \"index\": int(idx),\n",
    "                        \"file_name\": file_name,\n",
    "                        \"distance\": float(top_n_distances[i])\n",
    "                    })\n",
    "\n",
    "# Save the result as a JSON file\n",
    "output_json_path = 'ds_inf/vit_Kmeans++_closest_1_cluster_per_class.json'\n",
    "with open(output_json_path, 'w') as f:\n",
    "    json.dump(result, f, indent=4)\n",
    "\n",
    "print(f\"Result was saved in {output_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a802f8-4582-4748-ac24-2a49264fa386",
   "metadata": {},
   "source": [
    "# 质心最近的1个，`n_cluster=50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "026d095e-33a1-4631-9208-01e744df0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnid_to_index = load_mapping(os.path.join('ds_inf/tiny-imagenet-200', 'tiny-imagenet-mapping.txt'))\n",
    "input_dir = '/scratch/zhao.lin1/dataset/tiny-imagenet-200/train_vit_image_feature_CLS'\n",
    "save_dir = '/scratch/zhao.lin1/dataset/tiny-imagenet-200/key50_far_latents_train_vit_image_feature_CLS'\n",
    "n_clusters = 50\n",
    "n_key = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fd57655-a1cf-4264-8d47-0ad2abfce181",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = []\n",
    "labels = []\n",
    "file_paths = []\n",
    "result = {}  # Initialize result as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07053278-d867-4710-8fa0-cdd2ac8bb10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result was saved in ds_inf/vit_Kmeans++_closest_50_cluster_per_class.json\n"
     ]
    }
   ],
   "source": [
    "for class_idx, class_folder in enumerate(os.listdir(input_dir)):\n",
    "    class_dir = os.path.join(input_dir, class_folder)\n",
    "\n",
    "    if os.path.isdir(class_dir):\n",
    "        file_paths = []\n",
    "        latents = []\n",
    "\n",
    "        # Collect latents and file paths\n",
    "        for file_name in sorted(os.listdir(class_dir)):\n",
    "            if file_name.endswith('.pt'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                file_paths.append(file_path)\n",
    "                \n",
    "                latent = torch.load(file_path, weights_only=True)  \n",
    "                latents.append(latent.cpu().numpy())\n",
    "\n",
    "        # Process latents if any are found\n",
    "        if latents:\n",
    "            class_latents = np.stack(latents).astype(np.float32)\n",
    "            class_latents_normalized = normalize(class_latents, norm='l2', axis=1)\n",
    "\n",
    "            # Perform KMeans clustering\n",
    "            kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=0)\n",
    "            kmeans.fit(class_latents_normalized)\n",
    "            centroids = kmeans.cluster_centers_\n",
    "\n",
    "            # Calculate distances to the centroid for each latent in each cluster\n",
    "            distances = np.linalg.norm(class_latents_normalized - centroids[kmeans.labels_], axis=1)\n",
    "\n",
    "            # For each cluster, select the top n_key farthest latents\n",
    "            for cluster_idx in range(n_clusters):\n",
    "                # Get indices of latents belonging to the current cluster\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_idx)[0]\n",
    "                cluster_distances = distances[cluster_indices]\n",
    "                cluster_file_paths = [file_paths[i] for i in cluster_indices]\n",
    "\n",
    "                # Sort by distance and select top n_key latents\n",
    "                sorted_indices = np.argsort(cluster_distances)  # Sort descending by distance\n",
    "                top_n_indices = sorted_indices[:n_key]  # Select top n_key indices\n",
    "\n",
    "                top_n_distances = cluster_distances[top_n_indices]\n",
    "\n",
    "                # Ensure class key is in the result dictionary\n",
    "                key = class_folder\n",
    "                if key not in result:\n",
    "                    result[key] = []\n",
    "\n",
    "                # Append the result for the current cluster\n",
    "                for i in range(n_key):\n",
    "                    idx = cluster_indices[top_n_indices[i]]  # Get the original index of the latent\n",
    "                    file_name = os.path.basename(cluster_file_paths[i]).replace('.pt', '.JPEG')\n",
    "                    \n",
    "                    result[key].append({\n",
    "                        \"index\": int(idx),\n",
    "                        \"file_name\": file_name,\n",
    "                        \"distance\": float(top_n_distances[i])\n",
    "                    })\n",
    "\n",
    "# Save the result as a JSON file\n",
    "output_json_path = 'ds_inf/vit_Kmeans++_closest_50_cluster_per_class.json'\n",
    "with open(output_json_path, 'w') as f:\n",
    "    json.dump(result, f, indent=4)\n",
    "\n",
    "print(f\"Result was saved in {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5ee22-2153-46ae-ac2d-ef63636d3126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
